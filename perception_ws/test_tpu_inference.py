#!/usr/bin/env python3
"""
TPUæ¨ç†æµ‹è¯•è„šæœ¬
æµ‹è¯•ä¸‰ä¸ªEdgeTPUæ¨¡å‹çš„æ¨ç†æ€§èƒ½
"""

import numpy as np
import cv2
import time
import os
import sys

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.append('src/perception_pipeline')

try:
    from pycoral.utils import edgetpu
    from pycoral.adapters import common
    import tflite_runtime.interpreter as tflite
    TPU_AVAILABLE = True
    print("âœ… TPUåº“å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    TPU_AVAILABLE = False
    print(f"âŒ TPUåº“å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

def load_tpu_model(model_path):
    """åŠ è½½TPUæ¨¡å‹"""
    try:
        # å°è¯•ä½¿ç”¨EdgeTPU
        interpreter = tflite.Interpreter(
            model_path=model_path,
            experimental_delegates=[edgetpu.make_edgetpu_delegate()]
        )
        print(f"âœ… EdgeTPUæ¨¡å¼åŠ è½½: {os.path.basename(model_path)}")
    except:
        # å›é€€åˆ°CPU
        interpreter = tflite.Interpreter(model_path=model_path)
        print(f"âš ï¸ CPUæ¨¡å¼åŠ è½½: {os.path.basename(model_path)}")
    
    interpreter.allocate_tensors()
    return interpreter

def test_depth_model():
    """æµ‹è¯•æ·±åº¦ä¼°è®¡æ¨¡å‹"""
    print("\nğŸ” æµ‹è¯•æ·±åº¦ä¼°è®¡æ¨¡å‹...")
    model_path = "src/models/fastdepth_quantized_edgetpu.tflite"
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    interpreter = load_tpu_model(model_path)
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    
    print(f"è¾“å…¥å½¢çŠ¶: {input_details[0]['shape']}")
    print(f"è¾“å‡ºå½¢çŠ¶: {output_details[0]['shape']}")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    input_shape = input_details[0]['shape']
    test_image = np.random.randint(0, 255, input_shape, dtype=np.uint8)
    
    # æ¨ç†æµ‹è¯•
    start_time = time.time()
    interpreter.set_tensor(input_details[0]['index'], test_image)
    interpreter.invoke()
    depth_output = interpreter.get_tensor(output_details[0]['index'])
    inference_time = (time.time() - start_time) * 1000
    
    print(f"âš¡ æ·±åº¦ä¼°è®¡æ¨ç†æ—¶é—´: {inference_time:.2f}ms")
    print(f"âœ… è¾“å‡ºæ·±åº¦å›¾å½¢çŠ¶: {depth_output.shape}")

def test_detection_model():
    """æµ‹è¯•ç‰©ä½“æ£€æµ‹æ¨¡å‹"""
    print("\nğŸ¯ æµ‹è¯•ç‰©ä½“æ£€æµ‹æ¨¡å‹...")
    model_path = "src/models/ssd_mobilenet_v2_coco_quant_postprocess_edgetpu.tflite"
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    interpreter = load_tpu_model(model_path)
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    
    print(f"è¾“å…¥å½¢çŠ¶: {input_details[0]['shape']}")
    print(f"è¾“å‡ºæ•°é‡: {len(output_details)}")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    input_shape = input_details[0]['shape']
    test_image = np.random.randint(0, 255, input_shape, dtype=np.uint8)
    
    # æ¨ç†æµ‹è¯•
    start_time = time.time()
    interpreter.set_tensor(input_details[0]['index'], test_image)
    interpreter.invoke()
    
    # è·å–æ‰€æœ‰è¾“å‡º
    outputs = []
    for i, output_detail in enumerate(output_details):
        output = interpreter.get_tensor(output_detail['index'])
        outputs.append(output)
        print(f"è¾“å‡º {i} å½¢çŠ¶: {output.shape}")
    
    inference_time = (time.time() - start_time) * 1000
    print(f"âš¡ ç‰©ä½“æ£€æµ‹æ¨ç†æ—¶é—´: {inference_time:.2f}ms")

def test_segmentation_model():
    """æµ‹è¯•è¯­ä¹‰åˆ†å‰²æ¨¡å‹"""
    print("\nğŸ¨ æµ‹è¯•è¯­ä¹‰åˆ†å‰²æ¨¡å‹...")
    model_path = "src/models/deeplabv3_mnv2_pascal_quant_edgetpu.tflite"
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    interpreter = load_tpu_model(model_path)
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    
    print(f"è¾“å…¥å½¢çŠ¶: {input_details[0]['shape']}")
    print(f"è¾“å‡ºå½¢çŠ¶: {output_details[0]['shape']}")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    input_shape = input_details[0]['shape']
    test_image = np.random.randint(0, 255, input_shape, dtype=np.uint8)
    
    # æ¨ç†æµ‹è¯•
    start_time = time.time()
    interpreter.set_tensor(input_details[0]['index'], test_image)
    interpreter.invoke()
    segmentation_output = interpreter.get_tensor(output_details[0]['index'])
    inference_time = (time.time() - start_time) * 1000
    
    print(f"âš¡ è¯­ä¹‰åˆ†å‰²æ¨ç†æ—¶é—´: {inference_time:.2f}ms")
    print(f"âœ… è¾“å‡ºåˆ†å‰²å›¾å½¢çŠ¶: {segmentation_output.shape}")
    
    # åˆ†æåˆ†å‰²ç»“æœ
    seg_map = np.argmax(segmentation_output[0], axis=2)
    unique_classes = np.unique(seg_map)
    print(f"ğŸ·ï¸ æ£€æµ‹åˆ° {len(unique_classes)} ä¸ªç±»åˆ«: {unique_classes}")

def test_real_image_inference():
    """ä½¿ç”¨çœŸå®å›¾åƒè¿›è¡Œç«¯åˆ°ç«¯æµ‹è¯•"""
    print("\nğŸ–¼ï¸ çœŸå®å›¾åƒç«¯åˆ°ç«¯æµ‹è¯•...")
    
    # åˆ›å»ºä¸€ä¸ª640x480çš„æµ‹è¯•å›¾åƒ
    test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
    
    # æ·»åŠ ä¸€äº›ç»“æ„
    cv2.rectangle(test_image, (100, 100), (300, 200), (255, 0, 0), -1)  # è“è‰²çŸ©å½¢
    cv2.circle(test_image, (400, 300), 50, (0, 255, 0), -1)  # ç»¿è‰²åœ†å½¢
    cv2.rectangle(test_image, (200, 300), (500, 400), (0, 0, 255), 3)  # çº¢è‰²æ¡†
    
    print(f"æµ‹è¯•å›¾åƒå½¢çŠ¶: {test_image.shape}")
    
    # æµ‹è¯•æ¯ä¸ªæ¨¡å‹å¤„ç†ç›¸åŒå›¾åƒçš„æ—¶é—´
    models = [
        ("æ·±åº¦ä¼°è®¡", "src/models/fastdepth_quantized_edgetpu.tflite", (480, 640, 3)),
        ("ç‰©ä½“æ£€æµ‹", "src/models/ssd_mobilenet_v2_coco_quant_postprocess_edgetpu.tflite", (300, 300, 3)),
        ("è¯­ä¹‰åˆ†å‰²", "src/models/deeplabv3_mnv2_pascal_quant_edgetpu.tflite", (513, 513, 3))
    ]
    
    total_time = 0
    
    for model_name, model_path, input_size in models:
        if not os.path.exists(model_path):
            print(f"âŒ è·³è¿‡ {model_name}: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")
            continue
        
        # ç¼©æ”¾å›¾åƒåˆ°æ¨¡å‹è¾“å…¥å°ºå¯¸
        resized_image = cv2.resize(test_image, (input_size[1], input_size[0]))
        resized_image = np.expand_dims(resized_image, axis=0).astype(np.uint8)
        
        # åŠ è½½æ¨¡å‹å¹¶æ¨ç†
        interpreter = load_tpu_model(model_path)
        input_details = interpreter.get_input_details()
        
        start_time = time.time()
        interpreter.set_tensor(input_details[0]['index'], resized_image)
        interpreter.invoke()
        inference_time = (time.time() - start_time) * 1000
        
        total_time += inference_time
        print(f"âš¡ {model_name}: {inference_time:.2f}ms")
    
    print(f"\nğŸš€ æ€»æ¨ç†æ—¶é—´: {total_time:.2f}ms")
    print(f"ğŸ“Š ç†è®ºFPS: {1000/total_time:.1f}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ EdgeTPUæ¨ç†æ€§èƒ½æµ‹è¯•")
    print("=" * 50)
    
    # æ£€æŸ¥TPUè®¾å¤‡
    devices = edgetpu.list_edge_tpus()
    if devices:
        print(f"âœ… æ£€æµ‹åˆ° {len(devices)} ä¸ªEdgeTPUè®¾å¤‡")
        for i, device in enumerate(devices):
            print(f"   è®¾å¤‡ {i}: {device}")
    else:
        print("âš ï¸ æœªæ£€æµ‹åˆ°EdgeTPUè®¾å¤‡ï¼Œå°†ä½¿ç”¨CPUæ¨ç†")
    
    # é€ä¸ªæµ‹è¯•æ¨¡å‹
    try:
        test_depth_model()
        test_detection_model()
        test_segmentation_model()
        test_real_image_inference()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("ğŸ’¡ æç¤º: å¦‚æœçœ‹åˆ°CPUæ¨¡å¼ï¼Œè¯·è¿æ¥EdgeTPUè®¾å¤‡ä»¥è·å¾—æ›´å¥½æ€§èƒ½")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 